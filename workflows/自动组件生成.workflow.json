{
  "version": "1.0",
  "graph": {
    "graph": {
      "layout_direction": 0,
      "acyclic": true,
      "pipe_collision": false,
      "pipe_slicing": true,
      "pipe_style": 2,
      "accept_connection_types": "{}",
      "reject_connection_types": "{}"
    },
    "nodes": {
      "0x1fb4d995d50": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_大模型对话",
        "icon": null,
        "name": "大模型对话",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 525.0,
        "height": 515.3,
        "pos": [
          -670.6522729091892,
          1891.2941688118208
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "model": "qwen3-30b-a3b",
          "api_key": "",
          "base_url": "http://168.168.10.110:20000",
          "system_prompt": "你是一个代码编辑专家，能够根据用户的需求生成专业的python代码，除了python代码不要输出任何其他文字。",
          "temperature": 0.3,
          "max_tokens": "20000",
          "model_params": [
            {
              "key": "chat_template_kwargs",
              "value": "{\"enable_thinking\": false}"
            }
          ]
        }
      },
      "0x1fb67f1e9b0": {
        "type_": "dynamic.StatusDynamicNode_数据集成_长文本输入",
        "icon": null,
        "name": "组件意图",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 449.0,
        "height": 91.10000000000001,
        "pos": [
          -2188.57038571253,
          1543.8975222460185
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "input_text": "我的需求是开发一个大模型智能问题分类组件,根据全局变量中的model_name、url使用open_ai的工具包调用本地大模型"
        }
      },
      "0x1fb4da1ea70": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_JSON文本包装",
        "icon": null,
        "name": "JSON文本包装",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 339.0,
        "height": 91.10000000000001,
        "pos": [
          -1656.7402036036453,
          1547.2888474514596
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "prop_0": "intention"
        }
      },
      "0x1fb4da1d720": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_提示词模板",
        "icon": null,
        "name": "提示词模板 3",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 507.0,
        "height": 91.10000000000001,
        "pos": [
          -1160.223145640318,
          1703.264877421501
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "template": "## 组件开发需求\n{{intention}}\n\n## 组件输入参数\n{{input}}\n\n## 组件属性参数\n{{params}}\n\n## 组件输出参数\n{{output}}\n\n## 代码输出要求\n输出代码不需要包含输入、输出以及属性参数定义代码，这部分已经写好了，但是组件定义的输入输出参数必须要在当前参数定义范围之内，不能输出新的参数类型。同时第三方工具包导入时只能在函数内导入，不能在文件开头导入，不要引入Dict，List这些参数格式定义。\n\n## 生成的组件代码"
        }
      },
      "0x1fb4da3c2b0": {
        "type_": "dynamic.StatusDynamicNode_数据集成_长文本输入",
        "icon": null,
        "name": "组件输入",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 449.0,
        "height": 91.10000000000001,
        "pos": [
          -2188.2100495625027,
          1709.0080783870553
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "input_text": "输入是用户的问题文本"
        }
      },
      "0x1fb4da3c7c0": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_JSON文本包装",
        "icon": null,
        "name": "JSON文本包装 1",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 339.0,
        "height": 91.10000000000001,
        "pos": [
          -1687.4489383568828,
          1708.3496854337
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "prop_0": "input"
        }
      },
      "0x1fb4dca8d30": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_JSON文本包装",
        "icon": null,
        "name": "JSON文本包装 3",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 339.0,
        "height": 91.10000000000001,
        "pos": [
          -1667.8822547582986,
          1855.5505953710338
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "prop_0": "output"
        }
      },
      "0x1fb67ebef20": {
        "type_": "dynamic.StatusDynamicNode_数据集成_长文本输入",
        "icon": null,
        "name": "组件输出",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 449.0,
        "height": 91.10000000000001,
        "pos": [
          -2185.087885580765,
          1852.9496476217103
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "input_text": "输出是问题分类结果"
        }
      },
      "0x1fb67ebe4d0": {
        "type_": "dynamic.StatusDynamicNode_数据存储_组件保存",
        "icon": null,
        "name": "组件保存",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 160,
        "height": 60,
        "pos": [
          947.1487304459199,
          1888.5409078504013
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          }
        }
      },
      "0x1fb4dc56560": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_大模型输出解析",
        "icon": null,
        "name": "大模型输出解析",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 292.0,
        "height": 139.4,
        "pos": [
          573.7360894813451,
          1888.063894983026
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "strict": true,
          "type": "python"
        }
      },
      "0x1fb4dc570d0": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_移除思考过程",
        "icon": null,
        "name": "移除思考过程",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 455.0,
        "height": 103.7,
        "pos": [
          -7.780470444673426,
          1888.3933897249433
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "remove_empty_lines": true,
          "keep_inner_if_no_outer": true
        }
      },
      "0x1fb4dc54e80": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_构建多轮对话",
        "icon": null,
        "name": "构建多轮对话",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 499.0,
        "height": 375.65000000000003,
        "pos": [
          -1667.3915274262924,
          2158.593924881406
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "prop1": [
            {
              "role": "user",
              "content": "##  任务\n根据我的组件输入、输出、节点参数定义以及我的样例代码、需求等信息自动生成完整的python组件代码"
            },
            {
              "role": "assistant",
              "content": "好的，我会输出完整可运行的python代码"
            },
            {
              "role": "user",
              "content": "下面是组件输入、输出、属性端口定义代码，在组件中调用这些参数通过  参数类型.参数名 即可，所有参数均使用pydantic做了解析，全局变量使用 self.global_variable.变量名 直接在run里面就可以进行调用，不需要定义到property里：\n## 组件输入输出参数定义代码（不需要在生成代码里包含）\nclass ConnectionType(str, Enum):\n    \"\"\"连接类型\"\"\"\n    SINGLE = \"单输入\"\n    MULTIPLE = \"多输入\"\n\n\nclass PropertyType(str, Enum):\n    \"\"\"属性类型\"\"\"\n    TEXT = \"文本\"\n    MULTILINE = \"多行文本\"\n    LONGTEXT = \"长文本\"\n    INT = \"整数\"\n    FLOAT = \"浮点数\"\n    RANGE = \"范围\"\n    BOOL = \"复选框\"\n    CHOICE = \"下拉框\"\n    VARIABLE = \"全局变量\"\n    DYNAMICFORM = \"动态表单\"\n\n\nclass PropertyDefinition(BaseModel):\n    \"\"\"属性定义\"\"\"\n    type: PropertyType = PropertyType.TEXT\n    default: Any = \"\"\n    label: str = \"\"\n    choices: List[str] = Field(default_factory=list)\n    filter: str = \"All Files (*)\"  # 用于文件类型过滤\n    schema: Optional[Dict[str, 'PropertyDefinition']] = Field(default=None)  # 表单内每个字段的定义\n    min: float = Field(default=0.0, description=\"最小值\")\n    max: float = Field(default=100.0, description=\"最大值\")\n    step: float = Field(default=1.0, description=\"步长\")\n\n    class Config:\n        # 允许递归引用\n        arbitrary_types_allowed = True\n\n\nclass ArgumentType(str, Enum):\n    \"\"\"参数类型\"\"\"\n    TEXT = \"文本\"\n    INT = \"整数\"\n    FLOAT = \"浮点数\"\n    BOOL = \"布尔值\"\n    ARRAY = \"列表\"\n    CSV = \"csv\"\n    JSON = \"json\"\n    EXCEL = \"excel\"\n    FILE = \"文件\"\n    UPLOAD = \"上传\"\n    SKLEARNMODEL = \"sklearn模型\"\n    TORCHMODEL = \"torch模型\"\n    IMAGE = \"图片\"\n\n\nclass PortDefinition(BaseModel):\n    \"\"\"端口定义\"\"\"\n    name: str\n    label: str\n    type: ArgumentType = ArgumentType.TEXT\n    connection: ConnectionType = ConnectionType.SINGLE"
            },
            {
              "role": "assistant",
              "content": "好的，我已经了解了组件节点构成，我不会在生成的代码里包含该代码定义。"
            },
            {
              "role": "user",
              "content": "以下是组件的样例代码，仅供参考，所有的工具包导入均写在函数内：\nclass Component(BaseComponent):\n    name = \"构建多轮对话\"\n    category = \"大模型组件\"\n    description = \"用于构建符合大模型输入格式的多轮对话消息列表，支持追加新消息。\"\n    requirements = \"无特殊依赖，输出为标准 JSON 格式的对话列表。\"\n\n    inputs = [\n        PortDefinition(name=\"history\", label=\"输入1\", type=ArgumentType.JSON, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.JSON),\n    ]\n\n    properties = {\n        \"prop1\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"新增消息\",\n            schema={\n                \"role\": {\n                    \"type\": PropertyType.CHOICE.value,\n                    \"default\": \"user\",\n                    \"label\": \"角色\",\n                    \"choices\": [\"system\", \"user\", \"assistant\"]\n                },\n                \"content\": {\n                    \"type\": PropertyType.LONGTEXT.value,\n                    \"default\": \"\",\n                    \"label\": \"内容\",\n                },\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 获取历史对话（如果有的话）\n        history = inputs.get(\"history\") if inputs else None\n        if history is None:\n            history = []\n        # 组件内直接使用全局变量\n        model_name = self.global_variable.model_name\n\n        # 验证 history 是否为 list\n        if not isinstance(history, list):\n            history = []\n        self.logger.info(params.prop1)\n\n        # 获取用户配置的新消息\n        messages = history + [\n            {\n                \"role\": message.role,\n                \"content\": message.content\n            } for message in params.prop1\n        ]\n\n        # 返回符合大模型输入格式的对话列表\n        return {\n            \"output1\": messages  # 注意：必须与 outputs 中的 name 一致\n        }\n"
            },
            {
              "role": "assistant",
              "content": "好的，我已经了解了组件代码结构。"
            }
          ]
        }
      },
      "0x1fb4dadd7e0": {
        "type_": "dynamic.StatusDynamicNode_数据集成_获取全局变量",
        "icon": null,
        "name": "获取全局变量",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 372.0,
        "height": 100.55,
        "pos": [
          -771.6711397300485,
          2575.3300416613065
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {
              "大模型对话 response": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据用户输入的问题文本，使用大模型进行智能问题分类\"\n    requirements = \"numpy,pandas\"\n\n    inputs = [\n        PortDefinition(name=\"question\", label=\"用户问题文本\", type=ArgumentType.TEXT),\n    ]\n    outputs = [\n        PortDefinition(name=\"classification\", label=\"问题分类结果\", type=ArgumentArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"category_list\": PropertyDefinition(\n            type=PropertyType.LONGTEXT,\n            default=\"['技术问题', '业务咨询', '产品反馈', '功能请求', '其他']\",\n            label=\"分类列表\",\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        import re\n        import numpy\n        import pandas\n        self.logger.info(inputs)\n        question = inputs.get(\"question\", \"\") if inputs else \"\"\n        category_list = params.get(\"category_list\", \"['技术问题', '业务咨询', '产品反馈', '功能请求', '其他']\")\n        \n        # 将分类列表转换为Python列表\n        try:\n            category_list = eval(category_list)\n        except:\n            category_list = [\"技术问题\", \"业务咨询\", \"产品反馈\", \"功能请求\", \"其他\"]\n        \n        # 简单的分类逻辑（实际应使用大模型进行分类）\n        if any(keyword in question for keyword in [\"如何\", \"什么\", \"哪里\", \"当\", \"为什么\", \"怎样\"]):\n            classification = \"技术问题\"\n        elif any(keyword in question for keyword in [\"咨询\", \"了解\", \"信息\", \"帮助\"]):\n            classification = \"业务咨询\"\n        elif any(keyword in question for keyword in [\"反馈\", \"问题\", \"建议\"]):\n            classification = \"产品反馈\"\n        elif any(keyword in question for keyword in [\"请求\", \"需要\", \"想要\"]):\n            classification = \"功能请求\"\n        else:\n            classification = \"其他\"\n        \n        self.logger.info(f\"问题分类结果: {classification}\")\n        \n        return {\"classification\": classification}"
            }
          },
          "prop1": ""
        }
      },
      "0x1fb4dade770": {
        "type_": "dynamic.StatusDynamicNode_测试组件_添加字符串",
        "icon": null,
        "name": "添加字符串",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 382.0,
        "height": 100.55,
        "pos": [
          -1208.4088923345153,
          2740.216372807111
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "prop1": "custom.model_name"
        }
      },
      "0x1fb4db35420": {
        "type_": "dynamic.StatusDynamicNode_数据集成_文本输入",
        "icon": null,
        "name": "文本输入",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 405.0,
        "height": 258.05,
        "pos": [
          -2220.5069272597907,
          2703.6254480286525
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "input": "文本内容"
        }
      },
      "0x1fb4db370d0": {
        "type_": "control_flow.ControlFlowInputPort",
        "icon": null,
        "name": "输入端口",
        "color": [
          13,
          18,
          23,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 153.0,
        "height": 60,
        "pos": [
          -1411.4088923345153,
          2757.341372807111
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {}
        }
      },
      "0x1fb4db37f40": {
        "type_": "control_flow.ControlFlowOutputPort",
        "icon": null,
        "name": "输出端口",
        "color": [
          13,
          18,
          23,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 153.0,
        "height": 60,
        "pos": [
          -776.4088923345151,
          2757.341372807111
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {}
        }
      },
      "0x1fb4db345b0": {
        "type_": "control_flow.ControlFlowIterateNode",
        "icon": null,
        "name": "迭代控制流区域",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 868.0,
        "height": 174.25,
        "pos": [
          -1451.4088923345153,
          2700.216372807111
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "backdrop_text": "",
          "current_index": 4,
          "loop_nums": 4,
          "max_iterations": 1000
        }
      },
      "0x1fb4db349a0": {
        "type_": "dynamic.StatusDynamicNode_测试组件_逻辑判断",
        "icon": null,
        "name": "逻辑判断",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": true,
        "visible": true,
        "width": 648.0,
        "height": 287.45,
        "pos": [
          -1183.7037226113043,
          2906.9160852614446
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "conditions": [
            {
              "取反": "/",
              "变量": "$custom.model_name$",
              "操作符": "==",
              "常量": "$custom_model_name$"
            },
            {
              "取反": "/",
              "变量": "$ len(env.LANG) $",
              "操作符": ">",
              "常量": "0"
            }
          ],
          "组合方式": "and",
          "整体取反": false
        }
      },
      "0x1fb4d942ad0": {
        "type_": "dynamic.StatusDynamicNode_数据集成_文本输入",
        "icon": null,
        "name": "文本输入 1",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 417.0,
        "height": 258.05,
        "pos": [
          -2177.2175683246096,
          2287.706812317673
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "input": "$ len(custom.model_name) > 1$"
        }
      },
      "0x1fb4dd5c520": {
        "type_": "dynamic.StatusDynamicNode_数据集成_文本输入",
        "icon": null,
        "name": "文本输入 2",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 417.0,
        "height": 258.05,
        "pos": [
          -2665.686634268086,
          3161.14582500845
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "input": "测试1的伟大伟大·"
        }
      },
      "0x1fb4dd5ed40": {
        "type_": "dynamic.StatusDynamicNode_测试组件_逻辑判断",
        "icon": null,
        "name": "逻辑判断 1",
        "color": [
          13,
          18,
          23,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 648.0,
        "height": 232.85000000000002,
        "pos": [
          -795.5886163108859,
          3644.7072768705143
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {},
          "conditions": [
            {
              "取反": "/",
              "变量": "无",
              "操作符": ">",
              "常量": ""
            }
          ],
          "组合方式": "and",
          "整体取反": false
        }
      },
      "0x1fb4d9cb970": {
        "type_": "dynamic.StatusDynamicNode_数据集成_文本输入",
        "icon": null,
        "name": "文本输入 3",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 417.0,
        "height": 258.05,
        "pos": [
          -1329.145659707924,
          3633.314599787304
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "input": "文本内容"
        }
      },
      "0x1fb4d9ca110": {
        "type_": "dynamic.StatusDynamicNode_测试组件_逻辑判断",
        "icon": null,
        "name": "逻辑判断 2",
        "color": [
          80,
          30,
          30,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 648.0,
        "height": 232.85000000000002,
        "pos": [
          -775.5831423073042,
          3915.4246226725145
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "conditions": [
            {
              "取反": "/",
              "变量": "$len(input.var1)$",
              "操作符": ">",
              "常量": "1"
            }
          ],
          "组合方式": "and",
          "整体取反": false
        }
      },
      "0x1fb4dc00cd0": {
        "type_": "dynamic.StatusDynamicNode_测试组件_逻辑判断",
        "icon": null,
        "name": "逻辑判断 3",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 648.0,
        "height": 232.85000000000002,
        "pos": [
          -756.4621903338912,
          4170.065851390966
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "conditions": [
            {
              "取反": "/",
              "变量": "$len(input.var1)$",
              "操作符": ">",
              "常量": "1"
            }
          ],
          "组合方式": "and",
          "整体取反": false
        }
      },
      "0x1fb4dc2f250": {
        "type_": "dynamic.StatusDynamicNode_测试组件_逻辑判断",
        "icon": null,
        "name": "逻辑判断 4",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 648.0,
        "height": 232.85000000000002,
        "pos": [
          -804.6948506170454,
          4453.45870647364
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "conditions": [
            {
              "取反": "/",
              "变量": "$input.var1$",
              "操作符": "==",
              "常量": "文本内容"
            }
          ],
          "组合方式": "and",
          "整体取反": false
        }
      },
      "0x1fb4d917b50": {
        "type_": "control_flow.ControlFlowBranchNode",
        "icon": "D:\\work\\WorkFlowGUI\\./icons/条件分支.png",
        "name": "条件分支",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 509.0,
        "height": 163.55,
        "pos": [
          -97.59663234010583,
          4453.458706473639
        ],
        "layout_direction": 0,
        "port_deletion_allowed": true,
        "subgraph_session": {},
        "input_ports": [
          {
            "name": "input",
            "multi_connection": false,
            "display_name": true
          }
        ],
        "output_ports": [
          {
            "name": "else",
            "multi_connection": true,
            "display_name": true
          },
          {
            "name": "bra",
            "multi_connection": true,
            "display_name": true
          }
        ],
        "custom": {
          "global_variable": {},
          "enable_else": true,
          "conditions": [
            {
              "expr": "$input.input$",
              "name": "bra"
            }
          ]
        }
      },
      "0x1fb4d917910": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_JSON文本包装",
        "icon": null,
        "name": "JSON文本包装 2",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 339.0,
        "height": 91.10000000000001,
        "pos": [
          -1669.8002100537326,
          2004.5514178105504
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "prop_0": "output"
        }
      },
      "0x1fb4f9cd630": {
        "type_": "dynamic.StatusDynamicNode_数据集成_长文本输入",
        "icon": null,
        "name": "组件输出 1",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 461.0,
        "height": 91.10000000000001,
        "pos": [
          -2185.3341526793247,
          2001.950470061227
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "input_text": "组件参数是所有问题分类"
        }
      },
      "0x1fb4f9cc580": {
        "type_": "dynamic.StatusDynamicNode_测试组件_添加字符串",
        "icon": null,
        "name": "添加字符串 1",
        "color": [
          13,
          18,
          23,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 382.0,
        "height": 100.55,
        "pos": [
          -261.9747133702287,
          2730.9450336220243
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {},
          "prop1": "env.PYTHONPATH"
        }
      },
      "0x1fb4dd057b0": {
        "type_": "dynamic.StatusDynamicNode_数据存储_组件保存",
        "icon": null,
        "name": "组件保存 1",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 160,
        "height": 60,
        "pos": [
          2375.608454591062,
          2185.7569614096255
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          }
        }
      },
      "0x1fb4dd04670": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_移除思考过程",
        "icon": null,
        "name": "移除思考过程 1",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 455.0,
        "height": 103.7,
        "pos": [
          1420.6792537004687,
          2185.6094432841664
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "remove_empty_lines": true,
          "keep_inner_if_no_outer": true
        }
      },
      "0x1fb4dbd87f0": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_大模型输出解析",
        "icon": null,
        "name": "大模型输出解析 1",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 292.0,
        "height": 139.4,
        "pos": [
          2002.195813626487,
          2185.27994854225
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "strict": true,
          "type": "python"
        }
      },
      "0x1fb4dbd9750": {
        "type_": "dynamic.StatusDynamicNode_大模型组件_大模型对话",
        "icon": null,
        "name": "大模型对话 1",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 525.0,
        "height": 515.3,
        "pos": [
          743.3727061387776,
          2187.1979728167553
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "model": "qwen3-30b-a3b",
          "api_key": "",
          "base_url": "http://168.168.10.110:20000",
          "system_prompt": "你是一个代码编辑专家，能够根据用户的需求生成专业的python代码，除了python代码不要输出任何其他文字。",
          "temperature": 0.3,
          "max_tokens": "20000",
          "model_params": [
            {
              "key": "chat_template_kwargs",
              "value": "{\"enable_thinking\": false}"
            }
          ]
        }
      },
      "0x1fb4db64760": {
        "type_": "dynamic.StatusDynamicNode_数据集成_长文本输入",
        "icon": null,
        "name": "长文本输入",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 461.0,
        "height": 91.10000000000001,
        "pos": [
          269.59578274024113,
          2337.8836558236426
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {
            "env": {
              "user_id": null,
              "canvas_id": null,
              "session_id": null,
              "run_id": null,
              "metadata": {
                "PYTHONPATH": ".",
                "PYTHONUNBUFFERED": "1",
                "PYTHONIOENCODING": "utf-8",
                "PYTHONWARNINGS": "ignore",
                "TZ": "Asia/Shanghai",
                "LANG": "en_US.UTF-8",
                "OMP_NUM_THREADS": "1",
                "MKL_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
              }
            },
            "custom": {
              "model_name": {
                "value": "qwen3-30b-a3b",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "url": {
                "value": "http://168.168.10.110:20000",
                "description": null,
                "scope": "global",
                "read_only": false
              },
              "fets": {
                "value": "rfew",
                "description": null,
                "scope": "global",
                "read_only": false
              }
            },
            "node_vars": {}
          },
          "input_text": "有全局变量了就不需要在property上配置模型名称了呀，只需要用range类型控制下温度，还有你问题分类的配置呢，用动态表单动态创建问题分类，继续优化"
        }
      },
      "0x1fb4d9578e0": {
        "type_": "control_flow.ControlFlowInputPort",
        "icon": null,
        "name": "输入端口 1",
        "color": [
          13,
          18,
          23,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 165.0,
        "height": 60,
        "pos": [
          60.76370969227912,
          2134.6130982908753
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {}
        }
      },
      "0x1fb4d954490": {
        "type_": "control_flow.ControlFlowOutputPort",
        "icon": null,
        "name": "输出端口 1",
        "color": [
          13,
          18,
          23,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 165.0,
        "height": 60,
        "pos": [
          1357.8381437389485,
          2359.4529220964964
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {}
        }
      },
      "0x1fb4d954310": {
        "type_": "control_flow.ControlFlowIterateNode",
        "icon": null,
        "name": "迭代控制流区域 1",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 2869.844744898783,
        "height": 640.2768074151745,
        "pos": [
          20.76370969227912,
          2039.221165401581
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {},
          "backdrop_text": "",
          "current_index": 4,
          "loop_nums": 4,
          "max_iterations": 1000
        }
      },
      "0x1fb4d9540a0": {
        "type_": "dynamic.StatusDynamicNode_数据集成_文本输入",
        "icon": null,
        "name": "文本输入 4",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 417.0,
        "height": 258.05,
        "pos": [
          432.6547702344277,
          2960.0752070928297
        ],
        "layout_direction": 0,
        "port_deletion_allowed": false,
        "subgraph_session": {},
        "custom": {
          "global_variable": {},
          "input": "$custom.test$"
        }
      },
      "0x1fb4c06f2b0": {
        "type_": "control_flow.ControlFlowBranchNode",
        "icon": "D:\\work\\WorkFlowGUI\\./icons/条件分支.png",
        "name": "条件分支 1",
        "color": [
          25,
          70,
          45,
          255
        ],
        "border_color": [
          74,
          84,
          85,
          255
        ],
        "text_color": [
          255,
          255,
          255,
          180
        ],
        "disabled": false,
        "selected": false,
        "visible": true,
        "width": 279.0,
        "height": 128.9,
        "pos": [
          -1685.3299377252154,
          3043.101735851739
        ],
        "layout_direction": 0,
        "port_deletion_allowed": true,
        "subgraph_session": {},
        "input_ports": [
          {
            "name": "input",
            "multi_connection": false,
            "display_name": true
          }
        ],
        "output_ports": [
          {
            "name": "else",
            "multi_connection": true,
            "display_name": true
          }
        ],
        "custom": {
          "global_variable": {},
          "enable_else": true,
          "conditions": []
        }
      }
    },
    "connections": [
      {
        "in": [
          "0x1fb4d995d50",
          "user_input"
        ],
        "out": [
          "0x1fb4da1d720",
          "prompt"
        ]
      },
      {
        "in": [
          "0x1fb4d995d50",
          "history"
        ],
        "out": [
          "0x1fb4dc54e80",
          "output1"
        ]
      },
      {
        "out": [
          "0x1fb4d995d50",
          "response"
        ],
        "in": [
          "0x1fb4dc570d0",
          "raw_text"
        ]
      },
      {
        "out": [
          "0x1fb4d995d50",
          "history"
        ],
        "in": [
          "0x1fb4d954310",
          "inputs"
        ]
      },
      {
        "out": [
          "0x1fb67f1e9b0",
          "output"
        ],
        "in": [
          "0x1fb4da1ea70",
          "input1"
        ]
      },
      {
        "out": [
          "0x1fb4da1ea70",
          "output1"
        ],
        "in": [
          "0x1fb4da1d720",
          "variables"
        ]
      },
      {
        "in": [
          "0x1fb4da1d720",
          "variables"
        ],
        "out": [
          "0x1fb4da3c7c0",
          "output1"
        ]
      },
      {
        "in": [
          "0x1fb4da1d720",
          "variables"
        ],
        "out": [
          "0x1fb4dca8d30",
          "output1"
        ]
      },
      {
        "in": [
          "0x1fb4da1d720",
          "variables"
        ],
        "out": [
          "0x1fb4d917910",
          "output1"
        ]
      },
      {
        "out": [
          "0x1fb4da3c2b0",
          "output"
        ],
        "in": [
          "0x1fb4da3c7c0",
          "input1"
        ]
      },
      {
        "in": [
          "0x1fb4dca8d30",
          "input1"
        ],
        "out": [
          "0x1fb67ebef20",
          "output"
        ]
      },
      {
        "in": [
          "0x1fb67ebe4d0",
          "text"
        ],
        "out": [
          "0x1fb4dc56560",
          "parsed_json"
        ]
      },
      {
        "in": [
          "0x1fb4dc56560",
          "llm_output"
        ],
        "out": [
          "0x1fb4dc570d0",
          "cleaned_text"
        ]
      },
      {
        "in": [
          "0x1fb4dade770",
          "input1"
        ],
        "out": [
          "0x1fb4db370d0",
          "output"
        ]
      },
      {
        "out": [
          "0x1fb4dade770",
          "output1"
        ],
        "in": [
          "0x1fb4db37f40",
          "input"
        ]
      },
      {
        "out": [
          "0x1fb4db35420",
          "text"
        ],
        "in": [
          "0x1fb4db345b0",
          "inputs"
        ]
      },
      {
        "out": [
          "0x1fb4db35420",
          "text"
        ],
        "in": [
          "0x1fb4c06f2b0",
          "input"
        ]
      },
      {
        "in": [
          "0x1fb4db349a0",
          "var1"
        ],
        "out": [
          "0x1fb4c06f2b0",
          "else"
        ]
      },
      {
        "in": [
          "0x1fb4dd5ed40",
          "var1"
        ],
        "out": [
          "0x1fb4d9cb970",
          "text"
        ]
      },
      {
        "out": [
          "0x1fb4d9cb970",
          "text"
        ],
        "in": [
          "0x1fb4d9ca110",
          "var1"
        ]
      },
      {
        "out": [
          "0x1fb4d9cb970",
          "text"
        ],
        "in": [
          "0x1fb4dc00cd0",
          "var1"
        ]
      },
      {
        "out": [
          "0x1fb4d9cb970",
          "text"
        ],
        "in": [
          "0x1fb4dc2f250",
          "var1"
        ]
      },
      {
        "out": [
          "0x1fb4dc2f250",
          "output"
        ],
        "in": [
          "0x1fb4d917b50",
          "input"
        ]
      },
      {
        "in": [
          "0x1fb4d917910",
          "input1"
        ],
        "out": [
          "0x1fb4f9cd630",
          "output"
        ]
      },
      {
        "in": [
          "0x1fb4dd057b0",
          "text"
        ],
        "out": [
          "0x1fb4dbd87f0",
          "parsed_json"
        ]
      },
      {
        "in": [
          "0x1fb4dd04670",
          "raw_text"
        ],
        "out": [
          "0x1fb4dbd9750",
          "response"
        ]
      },
      {
        "out": [
          "0x1fb4dd04670",
          "cleaned_text"
        ],
        "in": [
          "0x1fb4dbd87f0",
          "llm_output"
        ]
      },
      {
        "in": [
          "0x1fb4dbd9750",
          "user_input"
        ],
        "out": [
          "0x1fb4db64760",
          "output"
        ]
      },
      {
        "in": [
          "0x1fb4dbd9750",
          "history"
        ],
        "out": [
          "0x1fb4d9578e0",
          "output"
        ]
      },
      {
        "out": [
          "0x1fb4dbd9750",
          "history"
        ],
        "in": [
          "0x1fb4d954490",
          "input"
        ]
      }
    ]
  },
  "runtime": {
    "environment": "3.11",
    "environment_exe": "D:\\work\\WorkFlowGUI\\envs\\miniconda\\envs\\3.11\\python.exe",
    "node_id2stable_key": {
      "0x1fb4d995d50": "大模型组件/大模型对话||大模型对话",
      "0x1fb67f1e9b0": "数据集成/长文本输入||组件意图",
      "0x1fb4da1ea70": "大模型组件/JSON文本包装||JSON文本包装",
      "0x1fb4da1d720": "大模型组件/提示词模板||提示词模板 3",
      "0x1fb4da3c2b0": "数据集成/长文本输入||组件输入",
      "0x1fb4da3c7c0": "大模型组件/JSON文本包装||JSON文本包装 1",
      "0x1fb4dca8d30": "大模型组件/JSON文本包装||JSON文本包装 3",
      "0x1fb67ebef20": "数据集成/长文本输入||组件输出",
      "0x1fb67ebe4d0": "数据存储/组件保存||组件保存",
      "0x1fb4dc56560": "大模型组件/大模型输出解析||大模型输出解析",
      "0x1fb4dc570d0": "大模型组件/移除思考过程||移除思考过程",
      "0x1fb4dc54e80": "大模型组件/构建多轮对话||构建多轮对话",
      "0x1fb4dadd7e0": "数据集成/获取全局变量||获取全局变量",
      "0x1fb4dade770": "测试组件/添加字符串||添加字符串",
      "0x1fb4db35420": "数据集成/文本输入||文本输入",
      "0x1fb4db370d0": "控制流/输入端口||输入端口",
      "0x1fb4db37f40": "控制流/输出端口||输出端口",
      "0x1fb4db349a0": "测试组件/逻辑判断||逻辑判断",
      "0x1fb4d942ad0": "数据集成/文本输入||文本输入 1",
      "0x1fb4dd5c520": "数据集成/文本输入||文本输入 2",
      "0x1fb4dd5ed40": "测试组件/逻辑判断||逻辑判断 1",
      "0x1fb4d9cb970": "数据集成/文本输入||文本输入 3",
      "0x1fb4d9ca110": "测试组件/逻辑判断||逻辑判断 2",
      "0x1fb4dc00cd0": "测试组件/逻辑判断||逻辑判断 3",
      "0x1fb4dc2f250": "测试组件/逻辑判断||逻辑判断 4",
      "0x1fb4d917b50": "控制流/条件分支||条件分支",
      "0x1fb4d917910": "大模型组件/JSON文本包装||JSON文本包装 2",
      "0x1fb4f9cd630": "数据集成/长文本输入||组件输出 1",
      "0x1fb4f9cc580": "测试组件/添加字符串||添加字符串 1",
      "0x1fb4dd057b0": "数据存储/组件保存||组件保存 1",
      "0x1fb4dd04670": "大模型组件/移除思考过程||移除思考过程 1",
      "0x1fb4dbd87f0": "大模型组件/大模型输出解析||大模型输出解析 1",
      "0x1fb4dbd9750": "大模型组件/大模型对话||大模型对话 1",
      "0x1fb4db64760": "数据集成/长文本输入||长文本输入",
      "0x1fb4d9578e0": "控制流/输入端口||输入端口 1",
      "0x1fb4d954490": "控制流/输出端口||输出端口 1",
      "0x1fb4d9540a0": "数据集成/文本输入||文本输入 4",
      "0x1fb4c06f2b0": "控制流/条件分支||条件分支 1"
    },
    "node_states": {
      "大模型组件/大模型对话||大模型对话": "success",
      "数据集成/长文本输入||组件意图": "success",
      "大模型组件/JSON文本包装||JSON文本包装": "success",
      "大模型组件/提示词模板||提示词模板 3": "success",
      "数据集成/长文本输入||组件输入": "success",
      "大模型组件/JSON文本包装||JSON文本包装 1": "success",
      "大模型组件/JSON文本包装||JSON文本包装 3": "success",
      "数据集成/长文本输入||组件输出": "success",
      "数据存储/组件保存||组件保存": "success",
      "大模型组件/大模型输出解析||大模型输出解析": "success",
      "大模型组件/移除思考过程||移除思考过程": "success",
      "大模型组件/构建多轮对话||构建多轮对话": "success",
      "数据集成/获取全局变量||获取全局变量": "success",
      "测试组件/添加字符串||添加字符串": "success",
      "数据集成/文本输入||文本输入": "success",
      "控制流/输入端口||输入端口": "unrun",
      "控制流/输出端口||输出端口": "unrun",
      "测试组件/逻辑判断||逻辑判断": "success",
      "数据集成/文本输入||文本输入 1": "success",
      "数据集成/文本输入||文本输入 2": "success",
      "测试组件/逻辑判断||逻辑判断 1": "unrun",
      "数据集成/文本输入||文本输入 3": "success",
      "测试组件/逻辑判断||逻辑判断 2": "failed",
      "测试组件/逻辑判断||逻辑判断 3": "success",
      "测试组件/逻辑判断||逻辑判断 4": "success",
      "控制流/条件分支||条件分支": "unrun",
      "大模型组件/JSON文本包装||JSON文本包装 2": "success",
      "数据集成/长文本输入||组件输出 1": "success",
      "测试组件/添加字符串||添加字符串 1": "unrun",
      "数据存储/组件保存||组件保存 1": "success",
      "大模型组件/移除思考过程||移除思考过程 1": "success",
      "大模型组件/大模型输出解析||大模型输出解析 1": "success",
      "大模型组件/大模型对话||大模型对话 1": "success",
      "数据集成/长文本输入||长文本输入": "success",
      "控制流/输入端口||输入端口 1": "unrun",
      "控制流/输出端口||输出端口 1": "unrun",
      "数据集成/文本输入||文本输入 4": "success",
      "控制流/条件分支||条件分支 1": "success"
    },
    "node_inputs": {
      "大模型组件/大模型对话||大模型对话": {},
      "数据集成/长文本输入||组件意图": {},
      "大模型组件/JSON文本包装||JSON文本包装": {},
      "大模型组件/提示词模板||提示词模板 3": {},
      "数据集成/长文本输入||组件输入": {},
      "大模型组件/JSON文本包装||JSON文本包装 1": {},
      "大模型组件/JSON文本包装||JSON文本包装 3": {},
      "数据集成/长文本输入||组件输出": {},
      "数据存储/组件保存||组件保存": {},
      "大模型组件/大模型输出解析||大模型输出解析": {},
      "大模型组件/移除思考过程||移除思考过程": {},
      "大模型组件/构建多轮对话||构建多轮对话": {},
      "数据集成/获取全局变量||获取全局变量": {},
      "测试组件/添加字符串||添加字符串": {},
      "数据集成/文本输入||文本输入": {},
      "控制流/输入端口||输入端口": {},
      "控制流/输出端口||输出端口": {},
      "测试组件/逻辑判断||逻辑判断": {},
      "数据集成/文本输入||文本输入 1": {},
      "数据集成/文本输入||文本输入 2": {},
      "测试组件/逻辑判断||逻辑判断 1": {},
      "数据集成/文本输入||文本输入 3": {},
      "测试组件/逻辑判断||逻辑判断 2": {},
      "测试组件/逻辑判断||逻辑判断 3": {},
      "测试组件/逻辑判断||逻辑判断 4": {},
      "控制流/条件分支||条件分支": {},
      "大模型组件/JSON文本包装||JSON文本包装 2": {},
      "数据集成/长文本输入||组件输出 1": {},
      "测试组件/添加字符串||添加字符串 1": {},
      "数据存储/组件保存||组件保存 1": {},
      "大模型组件/移除思考过程||移除思考过程 1": {},
      "大模型组件/大模型输出解析||大模型输出解析 1": {},
      "大模型组件/大模型对话||大模型对话 1": {},
      "数据集成/长文本输入||长文本输入": {},
      "控制流/输入端口||输入端口 1": {},
      "控制流/输出端口||输出端口 1": {},
      "数据集成/文本输入||文本输入 4": {},
      "控制流/条件分支||条件分支 1": {}
    },
    "node_outputs": {
      "大模型组件/大模型对话||大模型对话": {
        "response": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"model\": {\n                    \"type\": PropertyType.TEXT.value,\n                    \"default\": \"chatglm3\",\n                    \"label\": \"模型名称\"\n                },\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        prompt = f\"请对以下问题进行分类：\\n{user_input}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }",
        "raw_output": {
          "id": "chatcmpl-28fe50e1dcbd41aaa402de96d29c03fc",
          "choices": [
            {
              "finish_reason": "stop",
              "index": 0,
              "logprobs": null,
              "message": {
                "content": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"model\": {\n                    \"type\": PropertyType.TEXT.value,\n                    \"default\": \"chatglm3\",\n                    \"label\": \"模型名称\"\n                },\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        prompt = f\"请对以下问题进行分类：\\n{user_input}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }",
                "refusal": null,
                "role": "assistant",
                "annotations": null,
                "audio": null,
                "function_call": null,
                "tool_calls": [],
                "reasoning_content": null
              },
              "stop_reason": null,
              "token_ids": null
            }
          ],
          "created": 1760577210,
          "model": "qwen3-30b-a3b",
          "object": "chat.completion",
          "service_tier": null,
          "system_fingerprint": null,
          "usage": {
            "completion_tokens": 578,
            "prompt_tokens": 1265,
            "total_tokens": 1843,
            "completion_tokens_details": null,
            "prompt_tokens_details": null
          },
          "prompt_logprobs": null,
          "prompt_token_ids": null,
          "kv_transfer_params": null
        },
        "history": [
          {
            "role": "user",
            "content": "##  任务\n根据我的组件输入、输出、节点参数定义以及我的样例代码、需求等信息自动生成完整的python组件代码"
          },
          {
            "role": "assistant",
            "content": "好的，我会输出完整可运行的python代码"
          },
          {
            "role": "user",
            "content": "下面是组件输入、输出、属性端口定义代码，在组件中调用这些参数通过  参数类型.参数名 即可，所有参数均使用pydantic做了解析，全局变量使用 self.global_variable.变量名 直接在run里面就可以进行调用，不需要定义到property里：\n## 组件输入输出参数定义代码（不需要在生成代码里包含）\nclass ConnectionType(str, Enum):\n    \"\"\"连接类型\"\"\"\n    SINGLE = \"单输入\"\n    MULTIPLE = \"多输入\"\n\n\nclass PropertyType(str, Enum):\n    \"\"\"属性类型\"\"\"\n    TEXT = \"文本\"\n    MULTILINE = \"多行文本\"\n    LONGTEXT = \"长文本\"\n    INT = \"整数\"\n    FLOAT = \"浮点数\"\n    RANGE = \"范围\"\n    BOOL = \"复选框\"\n    CHOICE = \"下拉框\"\n    VARIABLE = \"全局变量\"\n    DYNAMICFORM = \"动态表单\"\n\n\nclass PropertyDefinition(BaseModel):\n    \"\"\"属性定义\"\"\"\n    type: PropertyType = PropertyType.TEXT\n    default: Any = \"\"\n    label: str = \"\"\n    choices: List[str] = Field(default_factory=list)\n    filter: str = \"All Files (*)\"  # 用于文件类型过滤\n    schema: Optional[Dict[str, 'PropertyDefinition']] = Field(default=None)  # 表单内每个字段的定义\n    min: float = Field(default=0.0, description=\"最小值\")\n    max: float = Field(default=100.0, description=\"最大值\")\n    step: float = Field(default=1.0, description=\"步长\")\n\n    class Config:\n        # 允许递归引用\n        arbitrary_types_allowed = True\n\n\nclass ArgumentType(str, Enum):\n    \"\"\"参数类型\"\"\"\n    TEXT = \"文本\"\n    INT = \"整数\"\n    FLOAT = \"浮点数\"\n    BOOL = \"布尔值\"\n    ARRAY = \"列表\"\n    CSV = \"csv\"\n    JSON = \"json\"\n    EXCEL = \"excel\"\n    FILE = \"文件\"\n    UPLOAD = \"上传\"\n    SKLEARNMODEL = \"sklearn模型\"\n    TORCHMODEL = \"torch模型\"\n    IMAGE = \"图片\"\n\n\nclass PortDefinition(BaseModel):\n    \"\"\"端口定义\"\"\"\n    name: str\n    label: str\n    type: ArgumentType = ArgumentType.TEXT\n    connection: ConnectionType = ConnectionType.SINGLE"
          },
          {
            "role": "assistant",
            "content": "好的，我已经了解了组件节点构成，我不会在生成的代码里包含该代码定义。"
          },
          {
            "role": "user",
            "content": "以下是组件的样例代码，仅供参考，所有的工具包导入均写在函数内：\nclass Component(BaseComponent):\n    name = \"构建多轮对话\"\n    category = \"大模型组件\"\n    description = \"用于构建符合大模型输入格式的多轮对话消息列表，支持追加新消息。\"\n    requirements = \"无特殊依赖，输出为标准 JSON 格式的对话列表。\"\n\n    inputs = [\n        PortDefinition(name=\"history\", label=\"输入1\", type=ArgumentType.JSON, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.JSON),\n    ]\n\n    properties = {\n        \"prop1\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"新增消息\",\n            schema={\n                \"role\": {\n                    \"type\": PropertyType.CHOICE.value,\n                    \"default\": \"user\",\n                    \"label\": \"角色\",\n                    \"choices\": [\"system\", \"user\", \"assistant\"]\n                },\n                \"content\": {\n                    \"type\": PropertyType.LONGTEXT.value,\n                    \"default\": \"\",\n                    \"label\": \"内容\",\n                },\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 获取历史对话（如果有的话）\n        history = inputs.get(\"history\") if inputs else None\n        if history is None:\n            history = []\n        # 组件内直接使用全局变量\n        model_name = self.global_variable.model_name\n\n        # 验证 history 是否为 list\n        if not isinstance(history, list):\n            history = []\n        self.logger.info(params.prop1)\n\n        # 获取用户配置的新消息\n        messages = history + [\n            {\n                \"role\": message.role,\n                \"content\": message.content\n            } for message in params.prop1\n        ]\n\n        # 返回符合大模型输入格式的对话列表\n        return {\n            \"output1\": messages  # 注意：必须与 outputs 中的 name 一致\n        }\n"
          },
          {
            "role": "assistant",
            "content": "好的，我已经了解了组件代码结构。"
          },
          {
            "role": "user",
            "content": "## 组件开发需求\n我的需求是开发一个大模型智能问题分类组件,根据全局变量中的model_name、url使用open_ai的工具包调用本地大模型\n\n## 组件输入参数\n输入是用户的问题文本\n\n## 组件属性参数\n{{params}}\n\n## 组件输出参数\n输出是问题分类结果\n\n## 代码输出要求\n输出代码不需要包含输入、输出以及属性参数定义代码，这部分已经写好了，但是组件定义的输入输出参数必须要在当前参数定义范围之内，不能输出新的参数类型。同时第三方工具包导入时只能在函数内导入，不能在文件开头导入，不要引入Dict，List这些参数格式定义。\n\n## 生成的组件代码"
          },
          {
            "role": "assistant",
            "content": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"model\": {\n                    \"type\": PropertyType.TEXT.value,\n                    \"default\": \"chatglm3\",\n                    \"label\": \"模型名称\"\n                },\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        prompt = f\"请对以下问题进行分类：\\n{user_input}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }"
          }
        ]
      },
      "数据集成/长文本输入||组件意图": {
        "output": "我的需求是开发一个大模型智能问题分类组件,根据全局变量中的model_name、url使用open_ai的工具包调用本地大模型"
      },
      "大模型组件/JSON文本包装||JSON文本包装": {
        "output1": {
          "intention": "我的需求是开发一个大模型智能问题分类组件,根据全局变量中的model_name、url使用open_ai的工具包调用本地大模型"
        }
      },
      "大模型组件/提示词模板||提示词模板 3": {
        "prompt": "## 组件开发需求\n我的需求是开发一个大模型智能问题分类组件,根据全局变量中的model_name、url使用open_ai的工具包调用本地大模型\n\n## 组件输入参数\n输入是用户的问题文本\n\n## 组件属性参数\n{{params}}\n\n## 组件输出参数\n输出是问题分类结果\n\n## 代码输出要求\n输出代码不需要包含输入、输出以及属性参数定义代码，这部分已经写好了，但是组件定义的输入输出参数必须要在当前参数定义范围之内，不能输出新的参数类型。同时第三方工具包导入时只能在函数内导入，不能在文件开头导入，不要引入Dict，List这些参数格式定义。\n\n## 生成的组件代码"
      },
      "数据集成/长文本输入||组件输入": {
        "output": "输入是用户的问题文本"
      },
      "大模型组件/JSON文本包装||JSON文本包装 1": {
        "output1": {
          "input": "输入是用户的问题文本"
        }
      },
      "大模型组件/JSON文本包装||JSON文本包装 3": {
        "output1": {
          "output": "输出是问题分类结果"
        }
      },
      "数据集成/长文本输入||组件输出": {
        "output": "输出是问题分类结果"
      },
      "数据存储/组件保存||组件保存": {
        "file_path": "D:\\work\\WorkFlowGUI\\app\\components\\generated\\generated_e4fdc680-9b8f-45e0-89cc-4b945e57b018.py"
      },
      "大模型组件/大模型输出解析||大模型输出解析": {
        "parsed_json": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"model\": {\n                    \"type\": PropertyType.TEXT.value,\n                    \"default\": \"chatglm3\",\n                    \"label\": \"模型名称\"\n                },\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        prompt = f\"请对以下问题进行分类：\\n{user_input}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }",
        "is_valid": true
      },
      "大模型组件/移除思考过程||移除思考过程": {
        "cleaned_text": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"model\": {\n                    \"type\": PropertyType.TEXT.value,\n                    \"default\": \"chatglm3\",\n                    \"label\": \"模型名称\"\n                },\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        prompt = f\"请对以下问题进行分类：\\n{user_input}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }",
        "think_text": ""
      },
      "大模型组件/构建多轮对话||构建多轮对话": {
        "output1": [
          {
            "role": "user",
            "content": "##  任务\n根据我的组件输入、输出、节点参数定义以及我的样例代码、需求等信息自动生成完整的python组件代码"
          },
          {
            "role": "assistant",
            "content": "好的，我会输出完整可运行的python代码"
          },
          {
            "role": "user",
            "content": "下面是组件输入、输出、属性端口定义代码，在组件中调用这些参数通过  参数类型.参数名 即可，所有参数均使用pydantic做了解析，全局变量使用 self.global_variable.变量名 直接在run里面就可以进行调用，不需要定义到property里：\n## 组件输入输出参数定义代码（不需要在生成代码里包含）\nclass ConnectionType(str, Enum):\n    \"\"\"连接类型\"\"\"\n    SINGLE = \"单输入\"\n    MULTIPLE = \"多输入\"\n\n\nclass PropertyType(str, Enum):\n    \"\"\"属性类型\"\"\"\n    TEXT = \"文本\"\n    MULTILINE = \"多行文本\"\n    LONGTEXT = \"长文本\"\n    INT = \"整数\"\n    FLOAT = \"浮点数\"\n    RANGE = \"范围\"\n    BOOL = \"复选框\"\n    CHOICE = \"下拉框\"\n    VARIABLE = \"全局变量\"\n    DYNAMICFORM = \"动态表单\"\n\n\nclass PropertyDefinition(BaseModel):\n    \"\"\"属性定义\"\"\"\n    type: PropertyType = PropertyType.TEXT\n    default: Any = \"\"\n    label: str = \"\"\n    choices: List[str] = Field(default_factory=list)\n    filter: str = \"All Files (*)\"  # 用于文件类型过滤\n    schema: Optional[Dict[str, 'PropertyDefinition']] = Field(default=None)  # 表单内每个字段的定义\n    min: float = Field(default=0.0, description=\"最小值\")\n    max: float = Field(default=100.0, description=\"最大值\")\n    step: float = Field(default=1.0, description=\"步长\")\n\n    class Config:\n        # 允许递归引用\n        arbitrary_types_allowed = True\n\n\nclass ArgumentType(str, Enum):\n    \"\"\"参数类型\"\"\"\n    TEXT = \"文本\"\n    INT = \"整数\"\n    FLOAT = \"浮点数\"\n    BOOL = \"布尔值\"\n    ARRAY = \"列表\"\n    CSV = \"csv\"\n    JSON = \"json\"\n    EXCEL = \"excel\"\n    FILE = \"文件\"\n    UPLOAD = \"上传\"\n    SKLEARNMODEL = \"sklearn模型\"\n    TORCHMODEL = \"torch模型\"\n    IMAGE = \"图片\"\n\n\nclass PortDefinition(BaseModel):\n    \"\"\"端口定义\"\"\"\n    name: str\n    label: str\n    type: ArgumentType = ArgumentType.TEXT\n    connection: ConnectionType = ConnectionType.SINGLE"
          },
          {
            "role": "assistant",
            "content": "好的，我已经了解了组件节点构成，我不会在生成的代码里包含该代码定义。"
          },
          {
            "role": "user",
            "content": "以下是组件的样例代码，仅供参考，所有的工具包导入均写在函数内：\nclass Component(BaseComponent):\n    name = \"构建多轮对话\"\n    category = \"大模型组件\"\n    description = \"用于构建符合大模型输入格式的多轮对话消息列表，支持追加新消息。\"\n    requirements = \"无特殊依赖，输出为标准 JSON 格式的对话列表。\"\n\n    inputs = [\n        PortDefinition(name=\"history\", label=\"输入1\", type=ArgumentType.JSON, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.JSON),\n    ]\n\n    properties = {\n        \"prop1\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"新增消息\",\n            schema={\n                \"role\": {\n                    \"type\": PropertyType.CHOICE.value,\n                    \"default\": \"user\",\n                    \"label\": \"角色\",\n                    \"choices\": [\"system\", \"user\", \"assistant\"]\n                },\n                \"content\": {\n                    \"type\": PropertyType.LONGTEXT.value,\n                    \"default\": \"\",\n                    \"label\": \"内容\",\n                },\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 获取历史对话（如果有的话）\n        history = inputs.get(\"history\") if inputs else None\n        if history is None:\n            history = []\n        # 组件内直接使用全局变量\n        model_name = self.global_variable.model_name\n\n        # 验证 history 是否为 list\n        if not isinstance(history, list):\n            history = []\n        self.logger.info(params.prop1)\n\n        # 获取用户配置的新消息\n        messages = history + [\n            {\n                \"role\": message.role,\n                \"content\": message.content\n            } for message in params.prop1\n        ]\n\n        # 返回符合大模型输入格式的对话列表\n        return {\n            \"output1\": messages  # 注意：必须与 outputs 中的 name 一致\n        }\n"
          },
          {
            "role": "assistant",
            "content": "好的，我已经了解了组件代码结构。"
          }
        ]
      },
      "数据集成/获取全局变量||获取全局变量": {
        "output1": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据用户输入的问题文本，使用大模型进行智能问题分类\"\n    requirements = \"numpy,pandas\"\n\n    inputs = [\n        PortDefinition(name=\"question\", label=\"用户问题文本\", type=ArgumentType.TEXT),\n    ]\n    outputs = [\n        PortDefinition(name=\"classification\", label=\"问题分类结果\", type=ArgumentArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"category_list\": PropertyDefinition(\n            type=PropertyType.LONGTEXT,\n            default=\"['技术问题', '业务咨询', '产品反馈', '功能请求', '其他']\",\n            label=\"分类列表\",\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        import re\n        import numpy\n        import pandas\n        self.logger.info(inputs)\n        question = inputs.get(\"question\", \"\") if inputs else \"\"\n        category_list = params.get(\"category_list\", \"['技术问题', '业务咨询', '产品反馈', '功能请求', '其他']\")\n        \n        # 将分类列表转换为Python列表\n        try:\n            category_list = eval(category_list)\n        except:\n            category_list = [\"技术问题\", \"业务咨询\", \"产品反馈\", \"功能请求\", \"其他\"]\n        \n        # 简单的分类逻辑（实际应使用大模型进行分类）\n        if any(keyword in question for keyword in [\"如何\", \"什么\", \"哪里\", \"当\", \"为什么\", \"怎样\"]):\n            classification = \"技术问题\"\n        elif any(keyword in question for keyword in [\"咨询\", \"了解\", \"信息\", \"帮助\"]):\n            classification = \"业务咨询\"\n        elif any(keyword in question for keyword in [\"反馈\", \"问题\", \"建议\"]):\n            classification = \"产品反馈\"\n        elif any(keyword in question for keyword in [\"请求\", \"需要\", \"想要\"]):\n            classification = \"功能请求\"\n        else:\n            classification = \"其他\"\n        \n        self.logger.info(f\"问题分类结果: {classification}\")\n        \n        return {\"classification\": classification}"
      },
      "测试组件/添加字符串||添加字符串": {
        "output1": "文本内容qwen3-30b-a3bqwen3-30b-a3bqwen3-30b-a3bqwen3-30b-a3b"
      },
      "数据集成/文本输入||文本输入": {
        "text": "文本内容"
      },
      "控制流/输入端口||输入端口": {},
      "控制流/输出端口||输出端口": {},
      "测试组件/逻辑判断||逻辑判断": {
        "output": true
      },
      "数据集成/文本输入||文本输入 1": {
        "text": "True"
      },
      "数据集成/文本输入||文本输入 2": {
        "text": "测试1的伟大伟大·"
      },
      "测试组件/逻辑判断||逻辑判断 1": {},
      "数据集成/文本输入||文本输入 3": {
        "text": "文本内容"
      },
      "测试组件/逻辑判断||逻辑判断 2": {},
      "测试组件/逻辑判断||逻辑判断 3": {
        "output": true
      },
      "测试组件/逻辑判断||逻辑判断 4": {
        "output": true
      },
      "控制流/条件分支||条件分支": {},
      "大模型组件/JSON文本包装||JSON文本包装 2": {
        "output1": {
          "output": "组件参数是所有问题分类"
        }
      },
      "数据集成/长文本输入||组件输出 1": {
        "output": "组件参数是所有问题分类"
      },
      "测试组件/添加字符串||添加字符串 1": {},
      "数据存储/组件保存||组件保存 1": {
        "file_path": "D:\\work\\WorkFlowGUI\\app\\components\\generated\\generated_beace99d-73df-4b59-871d-5dd31e720f53.py"
      },
      "大模型组件/移除思考过程||移除思考过程 1": {
        "cleaned_text": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                },\n                \"classification_rules\": {\n                    \"type\": PropertyType.DYNAMICFORM.value,\n                    \"label\": \"分类规则\",\n                    \"schema\": {\n                        \"rule1\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则1\",\n                            \"label\": \"规则1\"\n                        },\n                        \"rule2\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则2\",\n                            \"label\": \"规则2\"\n                        },\n                        \"rule3\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则3\",\n                            \"label\": \"规则3\"\n                        }\n                    }\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        rules = \"\\n\".join([f\"{key}: {value}\" for key, value in params.params.classification_rules.items()])\n        prompt = f\"请根据以下分类规则对以下问题进行分类：\\n{user_input}\\n\\n分类规则：\\n{rules}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }",
        "think_text": ""
      },
      "大模型组件/大模型输出解析||大模型输出解析 1": {
        "parsed_json": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                },\n                \"classification_rules\": {\n                    \"type\": PropertyType.DYNAMICFORM.value,\n                    \"label\": \"分类规则\",\n                    \"schema\": {\n                        \"rule1\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则1\",\n                            \"label\": \"规则1\"\n                        },\n                        \"rule2\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则2\",\n                            \"label\": \"规则2\"\n                        },\n                        \"rule3\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则3\",\n                            \"label\": \"规则3\"\n                        }\n                    }\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        rules = \"\\n\".join([f\"{key}: {value}\" for key, value in params.params.classification_rules.items()])\n        prompt = f\"请根据以下分类规则对以下问题进行分类：\\n{user_input}\\n\\n分类规则：\\n{rules}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }",
        "is_valid": true
      },
      "大模型组件/大模型对话||大模型对话 1": {
        "response": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                },\n                \"classification_rules\": {\n                    \"type\": PropertyType.DYNAMICFORM.value,\n                    \"label\": \"分类规则\",\n                    \"schema\": {\n                        \"rule1\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则1\",\n                            \"label\": \"规则1\"\n                        },\n                        \"rule2\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则2\",\n                            \"label\": \"规则2\"\n                        },\n                        \"rule3\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则3\",\n                            \"label\": \"规则3\"\n                        }\n                    }\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        rules = \"\\n\".join([f\"{key}: {value}\" for key, value in params.params.classification_rules.items()])\n        prompt = f\"请根据以下分类规则对以下问题进行分类：\\n{user_input}\\n\\n分类规则：\\n{rules}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }",
        "raw_output": {
          "id": "chatcmpl-68387ef405ef43179a2f83dfa71af935",
          "choices": [
            {
              "finish_reason": "stop",
              "index": 0,
              "logprobs": null,
              "message": {
                "content": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                },\n                \"classification_rules\": {\n                    \"type\": PropertyType.DYNAMICFORM.value,\n                    \"label\": \"分类规则\",\n                    \"schema\": {\n                        \"rule1\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则1\",\n                            \"label\": \"规则1\"\n                        },\n                        \"rule2\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则2\",\n                            \"label\": \"规则2\"\n                        },\n                        \"rule3\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则3\",\n                            \"label\": \"规则3\"\n                        }\n                    }\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        rules = \"\\n\".join([f\"{key}: {value}\" for key, value in params.params.classification_rules.items()])\n        prompt = f\"请根据以下分类规则对以下问题进行分类：\\n{user_input}\\n\\n分类规则：\\n{rules}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }",
                "refusal": null,
                "role": "assistant",
                "annotations": null,
                "audio": null,
                "function_call": null,
                "tool_calls": [],
                "reasoning_content": null
              },
              "stop_reason": null,
              "token_ids": null
            }
          ],
          "created": 1760577911,
          "model": "qwen3-30b-a3b",
          "object": "chat.completion",
          "service_tier": null,
          "system_fingerprint": null,
          "usage": {
            "completion_tokens": 719,
            "prompt_tokens": 4029,
            "total_tokens": 4748,
            "completion_tokens_details": null,
            "prompt_tokens_details": null
          },
          "prompt_logprobs": null,
          "prompt_token_ids": null,
          "kv_transfer_params": null
        },
        "history": [
          {
            "role": "user",
            "content": "##  任务\n根据我的组件输入、输出、节点参数定义以及我的样例代码、需求等信息自动生成完整的python组件代码"
          },
          {
            "role": "assistant",
            "content": "好的，我会输出完整可运行的python代码"
          },
          {
            "role": "user",
            "content": "下面是组件输入、输出、属性端口定义代码，在组件中调用这些参数通过  参数类型.参数名 即可，所有参数均使用pydantic做了解析，全局变量使用 self.global_variable.变量名 直接在run里面就可以进行调用，不需要定义到property里：\n## 组件输入输出参数定义代码（不需要在生成代码里包含）\nclass ConnectionType(str, Enum):\n    \"\"\"连接类型\"\"\"\n    SINGLE = \"单输入\"\n    MULTIPLE = \"多输入\"\n\n\nclass PropertyType(str, Enum):\n    \"\"\"属性类型\"\"\"\n    TEXT = \"文本\"\n    MULTILINE = \"多行文本\"\n    LONGTEXT = \"长文本\"\n    INT = \"整数\"\n    FLOAT = \"浮点数\"\n    RANGE = \"范围\"\n    BOOL = \"复选框\"\n    CHOICE = \"下拉框\"\n    VARIABLE = \"全局变量\"\n    DYNAMICFORM = \"动态表单\"\n\n\nclass PropertyDefinition(BaseModel):\n    \"\"\"属性定义\"\"\"\n    type: PropertyType = PropertyType.TEXT\n    default: Any = \"\"\n    label: str = \"\"\n    choices: List[str] = Field(default_factory=list)\n    filter: str = \"All Files (*)\"  # 用于文件类型过滤\n    schema: Optional[Dict[str, 'PropertyDefinition']] = Field(default=None)  # 表单内每个字段的定义\n    min: float = Field(default=0.0, description=\"最小值\")\n    max: float = Field(default=100.0, description=\"最大值\")\n    step: float = Field(default=1.0, description=\"步长\")\n\n    class Config:\n        # 允许递归引用\n        arbitrary_types_allowed = True\n\n\nclass ArgumentType(str, Enum):\n    \"\"\"参数类型\"\"\"\n    TEXT = \"文本\"\n    INT = \"整数\"\n    FLOAT = \"浮点数\"\n    BOOL = \"布尔值\"\n    ARRAY = \"列表\"\n    CSV = \"csv\"\n    JSON = \"json\"\n    EXCEL = \"excel\"\n    FILE = \"文件\"\n    UPLOAD = \"上传\"\n    SKLEARNMODEL = \"sklearn模型\"\n    TORCHMODEL = \"torch模型\"\n    IMAGE = \"图片\"\n\n\nclass PortDefinition(BaseModel):\n    \"\"\"端口定义\"\"\"\n    name: str\n    label: str\n    type: ArgumentType = ArgumentType.TEXT\n    connection: ConnectionType = ConnectionType.SINGLE"
          },
          {
            "role": "assistant",
            "content": "好的，我已经了解了组件节点构成，我不会在生成的代码里包含该代码定义。"
          },
          {
            "role": "user",
            "content": "以下是组件的样例代码，仅供参考，所有的工具包导入均写在函数内：\nclass Component(BaseComponent):\n    name = \"构建多轮对话\"\n    category = \"大模型组件\"\n    description = \"用于构建符合大模型输入格式的多轮对话消息列表，支持追加新消息。\"\n    requirements = \"无特殊依赖，输出为标准 JSON 格式的对话列表。\"\n\n    inputs = [\n        PortDefinition(name=\"history\", label=\"输入1\", type=ArgumentType.JSON, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.JSON),\n    ]\n\n    properties = {\n        \"prop1\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"新增消息\",\n            schema={\n                \"role\": {\n                    \"type\": PropertyType.CHOICE.value,\n                    \"default\": \"user\",\n                    \"label\": \"角色\",\n                    \"choices\": [\"system\", \"user\", \"assistant\"]\n                },\n                \"content\": {\n                    \"type\": PropertyType.LONGTEXT.value,\n                    \"default\": \"\",\n                    \"label\": \"内容\",\n                },\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 获取历史对话（如果有的话）\n        history = inputs.get(\"history\") if inputs else None\n        if history is None:\n            history = []\n        # 组件内直接使用全局变量\n        model_name = self.global_variable.model_name\n\n        # 验证 history 是否为 list\n        if not isinstance(history, list):\n            history = []\n        self.logger.info(params.prop1)\n\n        # 获取用户配置的新消息\n        messages = history + [\n            {\n                \"role\": message.role,\n                \"content\": message.content\n            } for message in params.prop1\n        ]\n\n        # 返回符合大模型输入格式的对话列表\n        return {\n            \"output1\": messages  # 注意：必须与 outputs 中的 name 一致\n        }\n"
          },
          {
            "role": "assistant",
            "content": "好的，我已经了解了组件代码结构。"
          },
          {
            "role": "user",
            "content": "## 组件开发需求\n我的需求是开发一个大模型智能问题分类组件,根据全局变量中的model_name、url使用open_ai的工具包调用本地大模型\n\n## 组件输入参数\n输入是用户的问题文本\n\n## 组件属性参数\n{{params}}\n\n## 组件输出参数\n输出是问题分类结果\n\n## 代码输出要求\n输出代码不需要包含输入、输出以及属性参数定义代码，这部分已经写好了，但是组件定义的输入输出参数必须要在当前参数定义范围之内，不能输出新的参数类型。同时第三方工具包导入时只能在函数内导入，不能在文件开头导入，不要引入Dict，List这些参数格式定义。\n\n## 生成的组件代码"
          },
          {
            "role": "assistant",
            "content": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"model\": {\n                    \"type\": PropertyType.TEXT.value,\n                    \"default\": \"chatglm3\",\n                    \"label\": \"模型名称\"\n                },\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        prompt = f\"请对以下问题进行分类：\\n{user_input}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }"
          },
          {
            "role": "user",
            "content": "有全局变量了就不需要在property上配置模型名称了呀，只需要用range类型控制下温度，还有你问题分类的配置呢，用动态表单动态创建问题分类，继续优化"
          },
          {
            "role": "assistant",
            "content": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        prompt = f\"请对以下问题进行分类：\\n{user_input}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }"
          },
          {
            "role": "user",
            "content": "有全局变量了就不需要在property上配置模型名称了呀，只需要用range类型控制下温度，还有你问题分类的配置呢，用动态表单动态创建问题分类，继续优化"
          },
          {
            "role": "assistant",
            "content": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                },\n                \"classification_rules\": {\n                    \"type\": PropertyType.DYNAMICFORM.value,\n                    \"label\": \"分类规则\",\n                    \"schema\": {\n                        \"rule1\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则1\",\n                            \"label\": \"规则1\"\n                        },\n                        \"rule2\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则2\",\n                            \"label\": \"规则2\"\n                        },\n                        \"rule3\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则3\",\n                            \"label\": \"规则3\"\n                        }\n                    }\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        prompt = f\"请根据以下分类规则对以下问题进行分类：\\n{user_input}\\n\\n分类规则：\\n{params.params.classification_rules.rule1}\\n{params.params.classification_rules.rule2}\\n{params.params.classification_rules.rule3}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }"
          },
          {
            "role": "user",
            "content": "有全局变量了就不需要在property上配置模型名称了呀，只需要用range类型控制下温度，还有你问题分类的配置呢，用动态表单动态创建问题分类，继续优化"
          },
          {
            "role": "assistant",
            "content": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                },\n                \"classification_rules\": {\n                    \"type\": PropertyType.DYNAMICFORM.value,\n                    \"label\": \"分类规则\",\n                    \"schema\": {\n                        \"rule1\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则1\",\n                            \"label\": \"规则1\"\n                        },\n                        \"rule2\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则2\",\n                            \"label\": \"规则2\"\n                        },\n                        \"rule3\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则3\",\n                            \"label\": \"规则3\"\n                        }\n                    }\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        rules = \"\\n\".join([f\"{key}: {value}\" for key, value in params.params.classification_rules.items()])\n        prompt = f\"请根据以下分类规则对以下问题进行分类：\\n{user_input}\\n\\n分类规则：\\n{rules}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }"
          },
          {
            "role": "user",
            "content": "有全局变量了就不需要在property上配置模型名称了呀，只需要用range类型控制下温度，还有你问题分类的配置呢，用动态表单动态创建问题分类，继续优化"
          },
          {
            "role": "assistant",
            "content": "class Component(BaseComponent):\n    name = \"大模型智能问题分类\"\n    category = \"大模型组件\"\n    description = \"根据全局变量中的model_name和url使用open_ai工具包调用本地大模型进行问题分类\"\n    requirements = \"需要open_ai工具包和本地大模型服务\"\n\n    inputs = [\n        PortDefinition(name=\"input1\", label=\"输入1\", type=ArgumentType.TEXT, connection=ConnectionType.SINGLE),\n    ]\n\n    outputs = [\n        PortDefinition(name=\"output1\", label=\"输出1\", type=ArgumentType.TEXT),\n    ]\n\n    properties = {\n        \"params\": PropertyDefinition(\n            type=PropertyType.DYNAMICFORM,\n            label=\"分类参数\",\n            schema={\n                \"temperature\": {\n                    \"type\": PropertyType.RANGE.value,\n                    \"default\": 0.7,\n                    \"label\": \"温度\",\n                    \"min\": 0.0,\n                    \"max\": 1.0,\n                    \"step\": 0.1\n                },\n                \"max_tokens\": {\n                    \"type\": PropertyType.INT.value,\n                    \"default\": 512,\n                    \"label\": \"最大生成长度\",\n                    \"min\": 1,\n                    \"max\": 2048\n                },\n                \"classification_rules\": {\n                    \"type\": PropertyType.DYNAMICFORM.value,\n                    \"label\": \"分类规则\",\n                    \"schema\": {\n                        \"rule1\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则1\",\n                            \"label\": \"规则1\"\n                        },\n                        \"rule2\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则2\",\n                            \"label\": \"规则2\"\n                        },\n                        \"rule3\": {\n                            \"type\": PropertyType.TEXT.value,\n                            \"default\": \"规则3\",\n                            \"label\": \"规则3\"\n                        }\n                    }\n                }\n            }\n        ),\n    }\n\n    def run(self, params, inputs = None):\n        \"\"\"\n        params: 节点属性（来自UI）\n        inputs: 上游输入（key=输入端口名）\n        return: 输出数据（key=输出端口名）\n        \"\"\"\n        # 导入open_ai工具包\n        import openai\n        \n        # 获取用户输入的问题文本\n        user_input = inputs.get(\"input1\") if inputs else \"\"\n        \n        # 获取全局变量中的model_name和url\n        model_name = self.global_variable.model_name\n        api_url = self.global_variable.url\n        \n        # 配置open_ai的API密钥和URL\n        openai.api_key = \"YOUR_API_KEY\"\n        openai.api_base = api_url\n        \n        # 构建提示词\n        rules = \"\\n\".join([f\"{key}: {value}\" for key, value in params.params.classification_rules.items()])\n        prompt = f\"请根据以下分类规则对以下问题进行分类：\\n{user_input}\\n\\n分类规则：\\n{rules}\"\n        \n        # 调用大模型进行分类\n        response = openai.ChatCompletion.create(\n            model=model_name,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=params.params.temperature,\n            max_tokens=params.params.max_tokens\n        )\n        \n        # 获取分类结果\n        classification_result = response.choices[0].message.content\n        \n        # 返回分类结果\n        return {\n            \"output1\": classification_result\n        }"
          }
        ]
      },
      "数据集成/长文本输入||长文本输入": {
        "output": "有全局变量了就不需要在property上配置模型名称了呀，只需要用range类型控制下温度，还有你问题分类的配置呢，用动态表单动态创建问题分类，继续优化"
      },
      "控制流/输入端口||输入端口 1": {},
      "控制流/输出端口||输出端口 1": {},
      "数据集成/文本输入||文本输入 4": {
        "text": ""
      },
      "控制流/条件分支||条件分支 1": {
        "else": {
          "input": "文本内容"
        },
        "branch": {
          "input": "文本内容"
        }
      }
    },
    "column_select": {
      "大模型组件/大模型对话||大模型对话": {},
      "数据集成/长文本输入||组件意图": {},
      "大模型组件/JSON文本包装||JSON文本包装": {},
      "大模型组件/提示词模板||提示词模板 3": {},
      "数据集成/长文本输入||组件输入": {},
      "大模型组件/JSON文本包装||JSON文本包装 1": {},
      "大模型组件/JSON文本包装||JSON文本包装 3": {},
      "数据集成/长文本输入||组件输出": {},
      "数据存储/组件保存||组件保存": {},
      "大模型组件/大模型输出解析||大模型输出解析": {},
      "大模型组件/移除思考过程||移除思考过程": {},
      "大模型组件/构建多轮对话||构建多轮对话": {},
      "数据集成/获取全局变量||获取全局变量": {},
      "测试组件/添加字符串||添加字符串": {},
      "数据集成/文本输入||文本输入": {},
      "控制流/输入端口||输入端口": {},
      "控制流/输出端口||输出端口": {},
      "测试组件/逻辑判断||逻辑判断": {},
      "数据集成/文本输入||文本输入 1": {},
      "数据集成/文本输入||文本输入 2": {},
      "测试组件/逻辑判断||逻辑判断 1": {},
      "数据集成/文本输入||文本输入 3": {},
      "测试组件/逻辑判断||逻辑判断 2": {},
      "测试组件/逻辑判断||逻辑判断 3": {},
      "测试组件/逻辑判断||逻辑判断 4": {},
      "控制流/条件分支||条件分支": {},
      "大模型组件/JSON文本包装||JSON文本包装 2": {},
      "数据集成/长文本输入||组件输出 1": {},
      "测试组件/添加字符串||添加字符串 1": {},
      "数据存储/组件保存||组件保存 1": {},
      "大模型组件/移除思考过程||移除思考过程 1": {},
      "大模型组件/大模型输出解析||大模型输出解析 1": {},
      "大模型组件/大模型对话||大模型对话 1": {},
      "数据集成/长文本输入||长文本输入": {},
      "控制流/输入端口||输入端口 1": {},
      "控制流/输出端口||输出端口 1": {},
      "数据集成/文本输入||文本输入 4": {},
      "控制流/条件分支||条件分支 1": {}
    }
  },
  "global_variable": {
    "env": {
      "user_id": null,
      "canvas_id": null,
      "session_id": null,
      "run_id": null,
      "metadata": {
        "PYTHONPATH": ".",
        "PYTHONUNBUFFERED": "1",
        "PYTHONIOENCODING": "utf-8",
        "PYTHONWARNINGS": "ignore",
        "TZ": "Asia/Shanghai",
        "LANG": "en_US.UTF-8",
        "OMP_NUM_THREADS": "1",
        "MKL_NUM_THREADS": "1",
        "CUDA_VISIBLE_DEVICES": "0"
      }
    },
    "custom": {
      "model_name": {
        "value": "qwen3-30b-a3b",
        "description": null,
        "scope": "global",
        "read_only": false
      },
      "url": {
        "value": "http://168.168.10.110:20000",
        "description": null,
        "scope": "global",
        "read_only": false
      },
      "fets": {
        "value": "rfew",
        "description": null,
        "scope": "global",
        "read_only": false
      },
      "test": {
        "value": 1,
        "description": null,
        "scope": "global",
        "read_only": false
      }
    },
    "node_vars": {}
  }
}